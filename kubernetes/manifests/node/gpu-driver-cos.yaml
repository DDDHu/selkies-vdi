# Copyright 2019 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# The Dockerfile and other source for this daemonset are in
# https://github.com/GoogleCloudPlatform/cos-gpu-installer
#
# This is the same as ../../daemonset.yaml except that it assumes that the
# docker image is present on the node instead of downloading from GCR. This
# allows easier upgrades because GKE can preload the correct image on the
# node and the daemonset can just use that image.

apiVersion: v1
kind: ServiceAccount
metadata:
  name: nvidia-driver-installer
  namespace: kube-system
  labels:
    app: nvidia-driver-installer
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: nvidia-driver-installer
  labels:
    app: nvidia-driver-installer
subjects:
  - kind: ServiceAccount
    name: nvidia-driver-installer
    namespace: kube-system
roleRef:
  kind: ClusterRole
  name: nvidia-driver-installer
  apiGroup: rbac.authorization.k8s.io
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: nvidia-driver-installer
  labels:
    app: nvidia-driver-installer
rules:
  - apiGroups: [""] # "" indicates the core API group
    resources: ["nodes"]
    verbs: ["*"]
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: nvidia-driver-installer
  namespace: kube-system
  labels:
    k8s-app: nvidia-driver-installer
spec:
  selector:
    matchLabels:
      k8s-app: nvidia-driver-installer
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        name: nvidia-driver-installer
        k8s-app: nvidia-driver-installer
    spec:
      # Service account with permissions to modify node when finished.
      serviceAccountName: nvidia-driver-installer
      # [START gpu_driver_scheduling]
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: cloud.google.com/gke-accelerator-initialized
                    operator: Exists
                  - key: cloud.google.com/gke-accelerator
                    operator: Exists
                  - key: cloud.google.com/gke-os-distribution
                    operator: In
                    values: ["cos"]
      tolerations:
        - key: "app.broker/node-init"
          effect: "NoSchedule"
          operator: "Exists"
        - key: "app.broker/tier"
          effect: "NoSchedule"
          operator: "Exists"
        - key: "cloud.google.com/gke-accelerator-init"
          effect: "NoSchedule"
          operator: "Exists"
        - key: "nvidia.com/gpu"
          effect: "NoSchedule"
          operator: "Exists"
      # [END gpu_driver_scheduling]
      hostNetwork: true
      hostPID: true
      volumes:
        - name: dev
          hostPath:
            path: /dev
        - name: nvidia-install-dir-host
          hostPath:
            path: /home/kubernetes/bin/nvidia
        - name: root-mount
          hostPath:
            path: /
        - name: config
          configMap:
            name: gpu-driver-cos
            defaultMode: 0755
      initContainers:
        - image: "cos-nvidia-installer:fixed"
          imagePullPolicy: Never
          name: nvidia-driver-installer
          resources:
            requests:
              cpu: 0.15
          securityContext:
            privileged: true
          env:
            - name: NVIDIA_INSTALL_DIR_HOST
              value: /home/kubernetes/bin/nvidia
            - name: NVIDIA_INSTALL_DIR_CONTAINER
              value: /usr/local/nvidia
            - name: ROOT_MOUNT_DIR
              value: /root
          volumeMounts:
            - name: nvidia-install-dir-host
              mountPath: /usr/local/nvidia
            - name: dev
              mountPath: /dev
            - name: root-mount
              mountPath: /root
            - name: config
              mountPath: /gpu_installer_url_lib.sh
              subPath: gpu_installer_url_lib.sh
            - name: config
              mountPath: /entrypoint.sh
              subPath: entrypoint.sh
        ###
        # Install CUDA package
        # Required for GStreamer cuda elements
        ###
        - name: cuda-install
          image: "cos-nvidia-installer:fixed"
          imagePullPolicy: Never
          securityContext:
            privileged: true
          volumeMounts:
            - name: root-mount
              mountPath: /usr/local/nvidia
              subPath: home/kubernetes/bin/nvidia
          env:
            - name: LD_LIBRARY_PATH
              value: "/usr/local/nvidia/lib64"
          command: ["/bin/bash"]
          args:
            - -exc
            - |
              apt-get update
              apt-get install -y curl libxml2

              cd /tmp
              curl -LO http://developer.download.nvidia.com/compute/cuda/10.1/Prod/local_installers/cuda_10.1.243_418.87.00_linux.run

              mkdir -p /usr/local/nvidia/cuda

              sh cuda_10.1.243_418.87.00_linux.run \
                --silent \
                --toolkit \
                --no-man-page \
                --no-drm \
                --no-opengl-libs \
                --installpath=/usr/local/nvidia/cuda

              touch /tmp/cuda_install_complete

        ###
        # Remove taint and update node label when finished.
        ###
        - name: node-init
          image: gcr.io/cloud-builders/kubectl:latest
          command: ["/bin/bash"]
          args:
            - -exc
            - |
              # remove taint
              kubectl taint node "${MY_NODE_NAME}" cloud.google.com/gke-accelerator-init:NoSchedule- || true

              # update node label to unschedule self
              kubectl label node "${MY_NODE_NAME}" --overwrite cloud.google.com/gke-accelerator-initialized=true
          env:
            - name: MY_NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
      containers:
        - image: "gcr.io/google-containers/pause:2.0"
          name: pause
